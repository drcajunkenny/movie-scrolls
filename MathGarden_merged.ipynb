{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(888)\n",
    "from tensorflow import random\n",
    "random.set_seed(404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from time import strftime\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_PATH = 'MNIST/digit_xtrain.csv'\n",
    "X_TEST_PATH = 'MNIST/digit_xtest.csv'\n",
    "Y_TRAIN_PATH = 'MNIST/digit_ytrain.csv'\n",
    "Y_TEST_PATH = 'MNIST/digit_ytest.csv'\n",
    "\n",
    "LOGGING_PATH = 'tensorboard_mnist_digit_logs/'\n",
    "\n",
    "NR_CLASSES = 10\n",
    "VALIDATION_SIZE = 10000\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "CHANNELS = 1\n",
    "TOTAL_INPUTS = IMAGE_WIDTH*IMAGE_HEIGHT*CHANNELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "y_train_all = np.loadtxt(Y_TRAIN_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.loadtxt(Y_TEST_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "x_train_all = np.loadtxt(X_TRAIN_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "x_test = np.loadtxt(X_TEST_PATH, delimiter=',', dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-scale\n",
    "x_train_all, x_test = x_train_all / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert target values to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = y_train_all[:5]\n",
    "np.eye(10)[values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(10)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all = np.eye(NR_CLASSES)[y_train_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.eye(NR_CLASSES)[y_test]\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation dataset from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train_all[:VALIDATION_SIZE]\n",
    "y_val = y_train_all[:VALIDATION_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_all[VALIDATION_SIZE:]\n",
    "y_train = y_train_all[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogImages(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, log_dir, x_data):\n",
    "        super(LogImages, self).__init__()\n",
    "        self.log_dir = log_dir\n",
    "        self.x_data = x_data \n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Log a batch of images at the end of an epoch\n",
    "        file_writer = tf.summary.create_file_writer(self.log_dir + '/images')\n",
    "\n",
    "        with file_writer.as_default():\n",
    "            images = np.reshape(self.x_data[:4], (-1, 28, 28, 1))  # Log 4 images\n",
    "            tf.summary.image(\"4 training data examples\", images, max_outputs=4, step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "img_path = '/Users/kenny/Documents/DS Projects/MathGarden/MNIST/test_img.png'\n",
    "\n",
    "img = load_img(img_path, color_mode='grayscale', target_size=(28, 28))\n",
    "\n",
    "img_array = img_to_array(img) / 255.0\n",
    "\n",
    "test_img = img_array.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Setup Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "# Neural network architecture parameters\n",
    "n_hidden1 = 512  \n",
    "n_hidden2 = 64   \n",
    "NR_CLASSES = 10  \n",
    "nr_epochs = 10   \n",
    "\n",
    "# Define the Model\n",
    "model = Sequential([\n",
    "    Dense(n_hidden1, activation='relu', input_shape=(TOTAL_INPUTS,), name='layer_1'),  # Note the input_shape adjustment\n",
    "    Dropout(0.2), \n",
    "    Dense(n_hidden2, activation='relu', name='layer_2'),\n",
    "    Dense(NR_CLASSES, activation='softmax', name='output_layer')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display model's architecture\n",
    "model.summary()\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(x_train, y_train, epochs=nr_epochs, batch_size=1000, validation_data=(x_val, y_val))\n",
    "\n",
    "# Evaluate the Model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}\")\n",
    "\n",
    "# Model Predictions\n",
    "predictions = model.predict(np.array([test_img])) \n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "print(f\"Prediction for test image is {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(n_hidden1, activation='relu', input_shape=(TOTAL_INPUTS,), name='layer_1'),\n",
    "    Dropout(0.2),\n",
    "    Dense(n_hidden2, activation='relu', name='layer_2'),\n",
    "    Dense(NR_CLASSES, activation='softmax', name='output_layer')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss, Optimisation & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Constants for the model\n",
    "n_hidden1 = 512  \n",
    "n_hidden2 = 64   \n",
    "NR_CLASSES = 10  \n",
    "TOTAL_INPUTS = 784 \n",
    "\n",
    "# Define the Model\n",
    "model = Sequential([\n",
    "    Dense(n_hidden1, activation='relu', input_shape=(TOTAL_INPUTS,), name='layer_1'),\n",
    "    Dropout(0.2), \n",
    "    Dense(n_hidden2, activation='relu', name='layer_2'),\n",
    "    Dense(NR_CLASSES, activation='softmax', name='output_layer')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display model's architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the batch size for training\n",
    "size_of_batch = 1000 \n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=nr_epochs,\n",
    "                    batch_size=size_of_batch,\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "print(history.history)\n",
    "\n",
    "# Evaluate the Model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# Load the image, ensuring it is in grayscale, and resize it to 28x28 pixels\n",
    "img = load_img('MNIST/test_img.png', color_mode='grayscale', target_size=(28, 28))\n",
    "\n",
    "# Convert the image to an array, normalize it, and possibly invert if required\n",
    "img_array = img_to_array(img) / 255.0\n",
    "\n",
    "# If your model was trained on inverted images, invert the pixel values\n",
    "# img_array = 1.0 - img_array\n",
    "\n",
    "# Flatten the array if your model expects flattened input\n",
    "test_img = img_array.flatten()\n",
    "\n",
    "# Make the prediction\n",
    "predictions = model.predict(np.array([test_img]))\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "print(f'Prediction for test image is {predicted_class}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f'Accuracy on test set is {test_accuracy:.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2731e71d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04068469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a51cb",
   "metadata": {},
   "source": [
    "# Seed for reproducing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(888)\n",
    "tf.random.set_seed(404)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec726f",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002714bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_PATH = 'MNIST/digit_xtrain.csv'\n",
    "X_TEST_PATH = 'MNIST/digit_xtest.csv'\n",
    "Y_TRAIN_PATH = 'MNIST/digit_ytrain.csv'\n",
    "Y_TEST_PATH = 'MNIST/digit_ytest.csv'\n",
    "NR_CLASSES = 10\n",
    "VALIDATION_SIZE = 10000\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "CHANNELS = 1\n",
    "TOTAL_INPUTS = IMAGE_WIDTH * IMAGE_HEIGHT * CHANNELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39f2263",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd50855",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all = np.loadtxt(Y_TRAIN_PATH, delimiter=',', dtype=int)\n",
    "x_train_all = np.loadtxt(X_TRAIN_PATH, delimiter=',', dtype=int)\n",
    "x_test = np.loadtxt(X_TEST_PATH, delimiter=',', dtype=int)\n",
    "y_test = np.loadtxt(Y_TEST_PATH, delimiter=',', dtype=int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0464c1f",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b3863",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all, x_test = x_train_all / 255.0, x_test / 255.0\n",
    "y_train_all = np.eye(NR_CLASSES)[y_train_all]\n",
    "y_test = np.eye(NR_CLASSES)[y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa3c63a",
   "metadata": {},
   "source": [
    "# Create validation dataset from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6367f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train_all[:VALIDATION_SIZE]\n",
    "y_val = y_train_all[:VALIDATION_SIZE]\n",
    "x_train = x_train_all[VALIDATION_SIZE:]\n",
    "y_train = y_train_all[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfe128",
   "metadata": {},
   "source": [
    "# Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813da82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebb86f7",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(TOTAL_INPUTS,)),\n",
    "    Dense(n_hidden1, activation='relu'),\n",
    "    Dropout(0.8),\n",
    "    Dense(n_hidden2, activation='relu'),\n",
    "    Dense(NR_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10797b",
   "metadata": {},
   "source": [
    "# Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ebd525",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db932bdc",
   "metadata": {},
   "source": [
    "# TensorBoard Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7aa400",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs\", \"fit\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acfe601",
   "metadata": {},
   "source": [
    "# Training the Model with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18932e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, \n",
    "    epochs=nr_epochs, \n",
    "    batch_size=1000, \n",
    "    validation_data=(x_val, y_val), \n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3e5a4",
   "metadata": {},
   "source": [
    "# Making a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7402b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    bw = img.convert('L')\n",
    "    img_array = np.invert(bw)\n",
    "    test_img = img_array.ravel() / 255.0\n",
    "    prediction = model.predict(np.array([test_img]))\n",
    "    return np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edead80a",
   "metadata": {},
   "source": [
    "# Example of making a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaab4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = make_prediction('MNIST/test_img.png')\n",
    "print(f'Prediction for test image is {prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8f64ad",
   "metadata": {},
   "source": [
    "# Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Seed for reproducing\n",
    "\n",
    "np.random.seed(888)\n",
    "tf.random.set_seed(404)\n",
    "\n",
    "# Constants\n",
    "\n",
    "X_TRAIN_PATH = 'MNIST/digit_xtrain.csv'\n",
    "X_TEST_PATH = 'MNIST/digit_xtest.csv'\n",
    "Y_TRAIN_PATH = 'MNIST/digit_ytrain.csv'\n",
    "Y_TEST_PATH = 'MNIST/digit_ytest.csv'\n",
    "NR_CLASSES = 10\n",
    "VALIDATION_SIZE = 10000\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "CHANNELS = 1\n",
    "TOTAL_INPUTS = IMAGE_WIDTH * IMAGE_HEIGHT * CHANNELS\n",
    "\n",
    "# Get the Data\n",
    "\n",
    "y_train_all = np.loadtxt(Y_TRAIN_PATH, delimiter=',', dtype=int)\n",
    "x_train_all = np.loadtxt(X_TRAIN_PATH, delimiter=',', dtype=int)\n",
    "x_test = np.loadtxt(X_TEST_PATH, delimiter=',', dtype=int)\n",
    "y_test = np.loadtxt(Y_TEST_PATH, delimiter=',', dtype=int)\n",
    "\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "x_train_all, x_test = x_train_all / 255.0, x_test / 255.0\n",
    "y_train_all = np.eye(NR_CLASSES)[y_train_all]\n",
    "y_test = np.eye(NR_CLASSES)[y_test]\n",
    "\n",
    "# Create validation dataset from training data\n",
    "\n",
    "x_val = x_train_all[:VALIDATION_SIZE]\n",
    "y_val = y_train_all[:VALIDATION_SIZE]\n",
    "x_train = x_train_all[VALIDATION_SIZE:]\n",
    "y_train = y_train_all[VALIDATION_SIZE:]\n",
    "\n",
    "# Neural Network Architecture\n",
    "\n",
    "nr_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 64\n",
    "\n",
    "# Define the Model\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(TOTAL_INPUTS,)),\n",
    "    Dense(n_hidden1, activation='relu'),\n",
    "    Dropout(0.8),\n",
    "    Dense(n_hidden2, activation='relu'),\n",
    "    Dense(NR_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# TensorBoard Setup\n",
    "\n",
    "log_dir = os.path.join(\"logs\", \"fit\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Training the Model with TensorBoard\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train, \n",
    "    epochs=nr_epochs, \n",
    "    batch_size=1000, \n",
    "    validation_data=(x_val, y_val), \n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "# Making a Prediction\n",
    "\n",
    "def make_prediction(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    bw = img.convert('L')\n",
    "    img_array = np.invert(bw)\n",
    "    test_img = img_array.ravel() / 255.0\n",
    "    prediction = model.predict(np.array([test_img]))\n",
    "    return np.argmax(prediction)\n",
    "\n",
    "# Example of making a prediction\n",
    "\n",
    "prediction = make_prediction('MNIST/test_img.png')\n",
    "print(f'Prediction for test image is {prediction}')\n",
    "\n",
    "# Testing and Evaluation\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c68ba1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0be4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2dc546",
   "metadata": {},
   "source": [
    "# Seed for reproducing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93903559",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(888)\n",
    "tf.random.set_seed(404)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf859a43",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c1d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_PATH = 'MNIST/digit_xtrain.csv'\n",
    "X_TEST_PATH = 'MNIST/digit_xtest.csv'\n",
    "Y_TRAIN_PATH = 'MNIST/digit_ytrain.csv'\n",
    "Y_TEST_PATH = 'MNIST/digit_ytest.csv'\n",
    "NR_CLASSES = 10\n",
    "VALIDATION_SIZE = 10000\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "CHANNELS = 1\n",
    "TOTAL_INPUTS = IMAGE_WIDTH * IMAGE_HEIGHT * CHANNELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9686c68",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef208d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all = np.loadtxt(Y_TRAIN_PATH, delimiter=',', dtype=int)\n",
    "x_train_all = np.loadtxt(X_TRAIN_PATH, delimiter=',', dtype=int)\n",
    "x_test = np.loadtxt(X_TEST_PATH, delimiter=',', dtype=int)\n",
    "y_test = np.loadtxt(Y_TEST_PATH, delimiter=',', dtype=int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2edf1d",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410111f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all, x_test = x_train_all / 255.0, x_test / 255.0\n",
    "y_train_all = np.eye(NR_CLASSES)[y_train_all]\n",
    "y_test = np.eye(NR_CLASSES)[y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50865d66",
   "metadata": {},
   "source": [
    "# Create validation dataset from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train_all[:VALIDATION_SIZE]\n",
    "y_val = y_train_all[:VALIDATION_SIZE]\n",
    "x_train = x_train_all[VALIDATION_SIZE:]\n",
    "y_train = y_train_all[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c700de3",
   "metadata": {},
   "source": [
    "# Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908b8ba3",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f73774",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(TOTAL_INPUTS,)),\n",
    "    Dense(n_hidden1, activation='relu'),\n",
    "    Dropout(0.8),\n",
    "    Dense(n_hidden2, activation='relu'),\n",
    "    Dense(NR_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d46cf37",
   "metadata": {},
   "source": [
    "# Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e76c5",
   "metadata": {},
   "source": [
    "# TensorBoard Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509a08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs\", \"fit\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9cd7fc",
   "metadata": {},
   "source": [
    "# Training the Model with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf94430",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, \n",
    "    epochs=nr_epochs, \n",
    "    batch_size=1000, \n",
    "    validation_data=(x_val, y_val), \n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5386310",
   "metadata": {},
   "source": [
    "# Making a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    bw = img.convert('L')\n",
    "    img_array = np.invert(bw)\n",
    "    test_img = img_array.ravel() / 255.0\n",
    "    prediction = model.predict(np.array([test_img]))\n",
    "    return np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48362ad2",
   "metadata": {},
   "source": [
    "# Example of making a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b54fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = make_prediction('MNIST/test_img.png')\n",
    "print(f'Prediction for test image is {prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca2b9c2",
   "metadata": {},
   "source": [
    "# Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a9a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TEST_PATH = 'MNIST/load_xtest.csv'\n",
    "Y_TEST_PATH = 'MNIST/load_ytest.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.loadtxt(Y_TEST_PATH, delimiter=',', dtype=int)\n",
    "x_test = np.loadtxt(X_TEST_PATH, delimiter=',', dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NR_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encode the Test Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_one_hot = np.eye(NR_CLASSES)[y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('SavedModel/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_classes[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_correct = sum(np.equal(predicted_classes, y_test))\n",
    "accuracy = nr_correct / len(predicted_classes)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model on the test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test_one_hot, verbose=2)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2731e71d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04068469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a51cb",
   "metadata": {},
   "source": [
    "# Seed for reproducing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(888)\n",
    "tf.random.set_seed(404)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec726f",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002714bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_PATH = 'MNIST/digit_xtrain.csv'\n",
    "X_TEST_PATH = 'MNIST/digit_xtest.csv'\n",
    "Y_TRAIN_PATH = 'MNIST/digit_ytrain.csv'\n",
    "Y_TEST_PATH = 'MNIST/digit_ytest.csv'\n",
    "NR_CLASSES = 10\n",
    "VALIDATION_SIZE = 10000\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "CHANNELS = 1\n",
    "TOTAL_INPUTS = IMAGE_WIDTH * IMAGE_HEIGHT * CHANNELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39f2263",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd50855",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_all = np.loadtxt(Y_TRAIN_PATH, delimiter=',', dtype=int)\n",
    "x_train_all = np.loadtxt(X_TRAIN_PATH, delimiter=',', dtype=int)\n",
    "x_test = np.loadtxt(X_TEST_PATH, delimiter=',', dtype=int)\n",
    "y_test = np.loadtxt(Y_TEST_PATH, delimiter=',', dtype=int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0464c1f",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b3863",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all, x_test = x_train_all / 255.0, x_test / 255.0\n",
    "y_train_all = np.eye(NR_CLASSES)[y_train_all]\n",
    "y_test = np.eye(NR_CLASSES)[y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa3c63a",
   "metadata": {},
   "source": [
    "# Create validation dataset from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6367f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train_all[:VALIDATION_SIZE]\n",
    "y_val = y_train_all[:VALIDATION_SIZE]\n",
    "x_train = x_train_all[VALIDATION_SIZE:]\n",
    "y_train = y_train_all[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfe128",
   "metadata": {},
   "source": [
    "# Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813da82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "n_hidden1 = 512\n",
    "n_hidden2 = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebb86f7",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(TOTAL_INPUTS,)),\n",
    "    Dense(n_hidden1, activation='relu'),\n",
    "    Dropout(0.8),\n",
    "    Dense(n_hidden2, activation='relu'),\n",
    "    Dense(NR_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef10797b",
   "metadata": {},
   "source": [
    "# Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ebd525",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db932bdc",
   "metadata": {},
   "source": [
    "# TensorBoard Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7aa400",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs\", \"fit\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acfe601",
   "metadata": {},
   "source": [
    "# Training the Model with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18932e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, \n",
    "    epochs=nr_epochs, \n",
    "    batch_size=1000, \n",
    "    validation_data=(x_val, y_val), \n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344c732",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d503d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('SavedModel/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3e5a4",
   "metadata": {},
   "source": [
    "# Making a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7402b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    bw = img.convert('L')\n",
    "    img_array = np.invert(bw)\n",
    "    test_img = img_array.ravel() / 255.0\n",
    "    prediction = model.predict(np.array([test_img]))\n",
    "    return np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edead80a",
   "metadata": {},
   "source": [
    "# Example of making a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaab4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = make_prediction('MNIST/test_img.png')\n",
    "print(f'Prediction for test image is {prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8f64ad",
   "metadata": {},
   "source": [
    "# Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
